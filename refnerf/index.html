<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Ref-NeuS</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://dorverbin.github.io/refnerf/img/refneus_titlecard.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://g3956.github.io">
    <meta property="og:title" content="Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields">
    <meta property="og:description" content="Neural implicit surface learning has shown significant progress in multi-view 3D reconstruction, where an object is represented by multilayer perceptrons that provide continuous implicit surface representation and view-dependent radiance. However, current methods often fail to accurately reconstruct reflective surfaces, leading to severe ambiguity. To overcome this issue, we propose Ref-NeuS, which aims to reduce ambiguity by attenuating the importance of reflective surfaces. Specifically, we utilize an anomaly detector to estimate an explicit reflection score with the guidance of multi-view context to localize reflective surfaces. Afterward, we design a reflection-aware photometric loss that adaptively reduces ambiguity by modeling rendered color as a Gaussian distribution, with the reflection score representing the variance. We show that together with a reflection direction-dependent radiance, our model achieves high-quality surface reconstruction on reflective surfaces and outperforms the state-of-the-arts by a large margin. Besides, our model is also comparable on general surfaces.">

    <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="col-md-12 text-center" id="title">
                <b>Ref-NeuS</b>: Ambiguity-Reduced Neural Implicit Surface Learning <br> for Multi-View Reconstruction with Reflection<br>
            </h2>
        </div>
        <div class="row" id="author-row" style="margin:0 auto;">
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="author-table">
                    <tr>
                        <td>
                            <a style="text-decoration:none">
                              Wenhang Ge
                            </a>
                            <br>HKUST (Guangzhou)
                        </td>
                        <td>
                            <a style="text-decoration:none" href="https://tau-yihouxiang.github.io/">
                              Tao Hu
                            </a>
                            <br>CUHK
                        </td>
                        <td>
                            <a style="text-decoration:none">
                             Haoyu Zhao
                            </a>
                            <br>HKUST (Guangzhou)
                        </td>
                    <tr>
                    <tr>
                        <td>
                            <a style="text-decoration:none" href="http://shuliu.me/">
                              Shu Liu
                            </a>
                            <br>Smartmore
                        </td>
                        <td>
                            <a style="text-decoration:none" href="https://www.yingcong.me/">
                              Ying-Cong Chen
                            </a>
                            <br>HKUST (Guangzhou)
                        </td>
                    </tr>
                </table>
            </div>
        </div>
    </div>
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script>
    <div class="container" id="main">
        <div class="row">
                <div class="col-sm-6 col-sm-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/pdf/2303.10840.pdf">
                            <img src="./img/paper_image.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li> 
                        <li>
                            <a href="https://github.com/g3956/Ref-NeuS" target="_blank">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>
    
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Neural implicit surface learning has shown significant progress in multi-view 3D reconstruction, where an object is represented by multilayer perceptrons that provide continuous implicit surface representation and view-dependent radiance. However, current methods often fail to accurately reconstruct reflective surfaces, leading to severe ambiguity. To overcome this issue, we propose Ref-NeuS, which aims to reduce ambiguity by attenuating the importance of reflective surfaces. Specifically, we utilize an anomaly detector to estimate an explicit reflection score with the guidance of multi-view context to localize reflective surfaces. Afterward, we design a reflection-aware photometric loss that adaptively reduces ambiguity by modeling rendered color as a Gaussian distribution, with the reflection score representing the variance. We show that together with a reflection direction-dependent radiance, our model achieves high-quality surface reconstruction on reflective surfaces and outperforms the state-of-the-arts by a large margin. Besides, our model is also comparable on general surfaces.
                </p>
            </div>
        </div>

        <image src="img/overall.png" class="img-responsive" alt="overview" width="60%" style="max-height: 450px;margin:auto;">

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Visual Results
                </h3>

                <table width="110%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <div class="video-compare-container" display:block>
                                <video class="video" id="toaster_mesh" loop playsinline autoPlay muted src="video/toaster_mesh_NeuS_our.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="toaster_meshMerge"></canvas>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <div class="video-compare-container" display:block>
                                <video class="video" id="toaster_normals" loop playsinline autoPlay muted src="video/helmet_meshes_NeuS_ours.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="toaster_normalsMerge"></canvas>
                            </div>
                        </td>
                    </tr>
                </table>

                <table width="110%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <div class="video-compare-container" display:block>
                                <video class="video" id="helmet_mesh" loop playsinline autoPlay muted src="video/toaster_normals_NeuS_ours.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="helmet_meshMerge"></canvas>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%" display:block>
                            <div class="video-compare-container">
                                <video class="video" id="helmet_normals" loop playsinline autoPlay muted src="video/helmet-normals_NeuS_ours.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="helmet_normalsMerge"></canvas>
                            </div>
                        </td>
                    </tr>
                </table>

			</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on Novel View Synthesis
                </h3>
                <div class="text-justify">
                    We show that our framework also excel at novel view synthesis thanks to the accurately eatimated surface normals.
                </div>

                <div class="video-compare-container">
                    <video class="video" id="helmet_render" loop playsinline autoPlay muted src="video/helmet_render_NeuS_our.mp4" onplay="resizeAndPlay(this)"></video>
                    <canvas height=0 class="videoMerge" id="helmet_renderMerge"></canvas>
                </div>

            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Additional Visual Results
                </h3>

                <div class="video-compare-container">
                    <video class="video" id="drums_mesh" loop playsinline autoPlay muted src="video/drums_comp.mp4" onplay="resizeAndPlay(this)"></video>
                    <canvas height=0 class="videoMerge" id="drums_meshMerge"></canvas>
                </div>

            </div>
        </div>

            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{ge2023ref,
    title={Ref-NeuS: Ambiguity-Reduced Neural Implicit Surface Learning for Multi-View Reconstruction with Reflection},
    author={Ge, Wenhang and Hu, Tao and Zhao, Haoyu and Liu, Shu and Chen, Ying-Cong},
    journal={arXiv preprint arXiv:2303.10840},
    year={2023}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                We would like to thank Dor Verbin and Kai Zhang for providing the dataset for evaluation and the results for comparison.
                    <br>
                The website template was borrowed from <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>.
                </p>
            </div>
        </div>
    </div>


</body></html>
